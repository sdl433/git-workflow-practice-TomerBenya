# Git Practice
## AI can predict which criminals may break laws again better than humans
I recently read an [article](https://www.sciencenews.org/article/ai-can-predict-criminals-repeat-offenders-better-than-humans) on _Science News_ about the use of AI to predict future criminal activity based on past data. I find the use of AI to predict human behavior absolutely fascinating and worthy of research, but when we start expecting to be able to make legal decisions based on the predictions made by such software it raises some big ethical questions about our relationship with technology. We've reached the age where AI and ML are becoming advanced enough to predict human behavior better than humans do, but as AI algorithms become more complex our understanding of how exactly they produce predictions diminishes. In my opinion, when it comes to upholding the law, AI based evidence definitely should be taken into account, but just like polygraph tests, which correctly detect that a person is lying only **87%** of the time (according to [this article](https://www.psychologytoday.com/us/blog/the-nature-deception/202001/do-lie-detector-tests-really-work) from *Psychology Today*), they should be taken with a grain of salt.

Comment from Zach Waxman: very interesting, thank you for sharing. We must be careful about applying technology to ethical questions.
